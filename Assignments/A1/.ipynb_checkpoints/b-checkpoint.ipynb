{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c25b279",
   "metadata": {},
   "source": [
    "# Q1: Regression Decision Tree Construction\n",
    "\n",
    "### Group Members: Pranav Mehrotra (20CS10085) and Saransh Sharma (20CS30065)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174c520",
   "metadata": {},
   "source": [
    "#### Import Required Libraries. To install Seaborn type in command pip install seaborn in the terminal. \n",
    "#### To run a cell press ctr + enter and press shift + enter to run a cell and move to next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d4988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a9275",
   "metadata": {},
   "source": [
    "#### Read the CSV file in the from of a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bed8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Train_B_Tree.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509f27a",
   "metadata": {},
   "source": [
    "#### Primary Analysis of the data read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20164610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
       "0   540.0    0.0     0.0  162.0               2.5           1040.0   \n",
       "1   540.0    0.0     0.0  162.0               2.5           1055.0   \n",
       "2   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "3   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "4   198.6  132.4     0.0  192.0               0.0            978.4   \n",
       "\n",
       "   fineaggregate  age  csMPa  \n",
       "0          676.0   28  79.99  \n",
       "1          676.0   28  61.89  \n",
       "2          594.0  270  40.27  \n",
       "3          594.0  365  41.05  \n",
       "4          825.5  360  44.30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea2e55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3712972",
   "metadata": {},
   "source": [
    "#### Check for duplicate data. Duplicate data doesn't help in training and so needs to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b282f617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>3</td>\n",
       "      <td>33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>3</td>\n",
       "      <td>33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>3</td>\n",
       "      <td>35.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>3</td>\n",
       "      <td>35.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>3</td>\n",
       "      <td>35.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>7</td>\n",
       "      <td>49.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>7</td>\n",
       "      <td>49.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>7</td>\n",
       "      <td>55.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>7</td>\n",
       "      <td>55.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>28</td>\n",
       "      <td>60.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>28</td>\n",
       "      <td>60.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>28</td>\n",
       "      <td>71.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>28</td>\n",
       "      <td>71.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>28</td>\n",
       "      <td>71.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>56</td>\n",
       "      <td>64.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>56</td>\n",
       "      <td>64.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>56</td>\n",
       "      <td>77.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>56</td>\n",
       "      <td>77.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>56</td>\n",
       "      <td>77.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>91</td>\n",
       "      <td>65.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>852.1</td>\n",
       "      <td>887.1</td>\n",
       "      <td>91</td>\n",
       "      <td>65.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>91</td>\n",
       "      <td>79.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>91</td>\n",
       "      <td>79.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>362.6</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>944.7</td>\n",
       "      <td>755.8</td>\n",
       "      <td>91</td>\n",
       "      <td>79.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>28</td>\n",
       "      <td>19.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
       "77    425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "80    425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "86    362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "88    362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "91    362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "100   425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "103   425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "109   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "111   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "123   425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "126   425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "132   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "134   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "137   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "146   425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "149   425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "155   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "157   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "160   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "169   425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "172   425.0  106.3     0.0  153.5              16.5            852.1   \n",
       "177   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "179   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "182   362.6  189.0     0.0  164.9              11.6            944.7   \n",
       "809   252.0    0.0     0.0  185.0               0.0           1111.0   \n",
       "\n",
       "     fineaggregate  age  csMPa  \n",
       "77           887.1    3  33.40  \n",
       "80           887.1    3  33.40  \n",
       "86           755.8    3  35.30  \n",
       "88           755.8    3  35.30  \n",
       "91           755.8    3  35.30  \n",
       "100          887.1    7  49.20  \n",
       "103          887.1    7  49.20  \n",
       "109          755.8    7  55.90  \n",
       "111          755.8    7  55.90  \n",
       "123          887.1   28  60.29  \n",
       "126          887.1   28  60.29  \n",
       "132          755.8   28  71.30  \n",
       "134          755.8   28  71.30  \n",
       "137          755.8   28  71.30  \n",
       "146          887.1   56  64.30  \n",
       "149          887.1   56  64.30  \n",
       "155          755.8   56  77.30  \n",
       "157          755.8   56  77.30  \n",
       "160          755.8   56  77.30  \n",
       "169          887.1   91  65.20  \n",
       "172          887.1   91  65.20  \n",
       "177          755.8   91  79.30  \n",
       "179          755.8   91  79.30  \n",
       "182          755.8   91  79.30  \n",
       "809          784.0   28  19.69  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30583f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6407638c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2082220b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1005 entries, 0 to 1029\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   cement            1005 non-null   float64\n",
      " 1   slag              1005 non-null   float64\n",
      " 2   flyash            1005 non-null   float64\n",
      " 3   water             1005 non-null   float64\n",
      " 4   superplasticizer  1005 non-null   float64\n",
      " 5   coarseaggregate   1005 non-null   float64\n",
      " 6   fineaggregate     1005 non-null   float64\n",
      " 7   age               1005 non-null   int64  \n",
      " 8   csMPa             1005 non-null   float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 78.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537937cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>278.631343</td>\n",
       "      <td>72.043483</td>\n",
       "      <td>55.536318</td>\n",
       "      <td>182.075323</td>\n",
       "      <td>6.033234</td>\n",
       "      <td>974.376816</td>\n",
       "      <td>772.688259</td>\n",
       "      <td>45.856716</td>\n",
       "      <td>35.250378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.344261</td>\n",
       "      <td>86.170807</td>\n",
       "      <td>64.207969</td>\n",
       "      <td>21.339334</td>\n",
       "      <td>5.919967</td>\n",
       "      <td>77.579667</td>\n",
       "      <td>80.340435</td>\n",
       "      <td>63.734692</td>\n",
       "      <td>16.284815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>190.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>166.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>724.300000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>265.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.700000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>33.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>349.000000</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.900000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1031.000000</td>\n",
       "      <td>822.200000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>44.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cement         slag       flyash        water  superplasticizer  \\\n",
       "count  1005.000000  1005.000000  1005.000000  1005.000000       1005.000000   \n",
       "mean    278.631343    72.043483    55.536318   182.075323          6.033234   \n",
       "std     104.344261    86.170807    64.207969    21.339334          5.919967   \n",
       "min     102.000000     0.000000     0.000000   121.800000          0.000000   \n",
       "25%     190.700000     0.000000     0.000000   166.600000          0.000000   \n",
       "50%     265.000000    20.000000     0.000000   185.700000          6.100000   \n",
       "75%     349.000000   142.500000   118.300000   192.900000         10.000000   \n",
       "max     540.000000   359.400000   200.100000   247.000000         32.200000   \n",
       "\n",
       "       coarseaggregate  fineaggregate          age        csMPa  \n",
       "count      1005.000000    1005.000000  1005.000000  1005.000000  \n",
       "mean        974.376816     772.688259    45.856716    35.250378  \n",
       "std          77.579667      80.340435    63.734692    16.284815  \n",
       "min         801.000000     594.000000     1.000000     2.330000  \n",
       "25%         932.000000     724.300000     7.000000    23.520000  \n",
       "50%         968.000000     780.000000    28.000000    33.800000  \n",
       "75%        1031.000000     822.200000    56.000000    44.870000  \n",
       "max        1145.000000     992.600000   365.000000    82.600000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1fe1c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cement              0\n",
       "slag                0\n",
       "flyash              0\n",
       "water               0\n",
       "superplasticizer    0\n",
       "coarseaggregate     0\n",
       "fineaggregate       0\n",
       "age                 0\n",
       "csMPa               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab818e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4095d70",
   "metadata": {},
   "source": [
    "#### Feature Matrix of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884b30e",
   "metadata": {},
   "source": [
    "#### Output Vector of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153ece3",
   "metadata": {},
   "source": [
    "#### To visualise the kernel density (peaks in the data) of the individual features and to visualise the distributions' median, 25 percentile and 75 percentile quartiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f34ea",
   "metadata": {},
   "source": [
    "#### To visualize individual  features' kernel density and pairwise scatter plots to look for correlation between different features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39e978",
   "metadata": {},
   "source": [
    "#### To view how related two features are we plot the heatmap which actually represents the correlation of two features.  Correlation of 1 represents very strong positive correlation and correlation of -1 represents very strong negative correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47632a",
   "metadata": {},
   "source": [
    "#### Let us individually analyse the feature pair with the highest absolute value of correlation to check if the feature vectors are linearly dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9a47e",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e18886",
   "metadata": {},
   "source": [
    "#### Dataframe Data contains the data read from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "500b8b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
       "0   540.0    0.0     0.0  162.0               2.5           1040.0   \n",
       "1   540.0    0.0     0.0  162.0               2.5           1055.0   \n",
       "2   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "3   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "4   198.6  132.4     0.0  192.0               0.0            978.4   \n",
       "\n",
       "   fineaggregate  age  csMPa  \n",
       "0          676.0   28  79.99  \n",
       "1          676.0   28  61.89  \n",
       "2          594.0  270  40.27  \n",
       "3          594.0  365  41.05  \n",
       "4          825.5  360  44.30  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2504f3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff4450",
   "metadata": {},
   "source": [
    "#### The model is basically a tree containing nodes and edges. There exist two types of nodes in the tree. Leaf nodes and decision nodes. Leaf nodes are the nodes which would be helpful in case of predicting (outputting the final value) while decision nodes will represent set of conditions that would help us to make a decision about the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a0d8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, attribute=None, threshold=None, child_left=None, child_right=None, variance_red=None, level = 0, leaf_value=None):\n",
    "        \n",
    "        # data members corresponding to decision nodes\n",
    "        self.attribute = attribute\n",
    "        self.threshold = threshold\n",
    "        self.child_left = child_left\n",
    "        self.child_right = child_right\n",
    "        self.variance_red = variance_red\n",
    "        self.level = level\n",
    "        \n",
    "        #data member corresponding to a leaf node\n",
    "        self.leaf_value = leaf_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a69979",
   "metadata": {},
   "source": [
    "##### Kindly note: We have used the same defination of node for both the types of node. A decision node would have leaf_value = None while a leaf_node would have a numerical leaf_value. This difference would help us to differentiate between a leaf node and a decision node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3efebe",
   "metadata": {},
   "source": [
    "#### Class defination of a regression tree which will encapsulate all the functions and operation needed to construct a regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b9023ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RegressionTree():\n",
    "    def __init__(self, minimum_samples=2, max_depth=2): #constructor that will take two parameters\n",
    " \n",
    "        self.root = None\n",
    "        self.minimum_samples = minimum_samples #min number of samples that should be available for further splitting\n",
    "        self.max_depth = max_depth #max- depth the tree is allowed to grow\n",
    "        #these two parameters act as stopping conditions for the tree\n",
    "        \n",
    "    def variance_reduction(self, parent, left_branch, right_branch): #to find the reduction in variance\n",
    "        \n",
    "        fraction_left = len(left_branch) / len(parent) #fraction of original data in the left branch\n",
    "        fraction_right = len(right_branch) / len(parent) #fraction of original data in right branch\n",
    "        reduction_variance = np.var(parent) - (fraction_left * np.var(left_branch) + fraction_right * np.var(right_branch))\n",
    "        #variance reduction is defined as variance of original data - weighted sum of variance of branches\n",
    "        return reduction_variance\n",
    "    \n",
    "    def split_left_right(self, dataset, index, threshold): #to split the data in two branches depending upon attribute denoted by index and threshold\n",
    "        \n",
    "        left_dataset = np.array([x for x in dataset if x[index]<=threshold]) #left dataset contains all datapoints whose value of the specified attribute is less than or equal to threshold\n",
    "        right_dataset = np.array([x for x in dataset if x[index]>threshold]) #right dataset contains all datapoints whose value of the specified attribute is more than threshold\n",
    "        return left_dataset, right_dataset #return the two partitions\n",
    "    \n",
    "    def cal_leaf_node(self, y):#to calculate the value of a leaf node simple calculate mean of all the datapoints's y value at that node \n",
    "        \n",
    "        leaf_val = np.mean(y)\n",
    "        return leaf_val\n",
    "                \n",
    "    def get_best_feature(self, dataset, number_datapoints, number_attributes): # to get the feature and threshold with maximum variance reduction\n",
    "        \n",
    "        #initialise best_feature dictionary\n",
    "        best_feature = {}\n",
    "        best_feature[\"attribute\"] = None\n",
    "        best_feature[\"threshold\"] = 0\n",
    "        best_feature[\"dataset_left\"] = None\n",
    "        best_feature[\"dataset_right\"] = None\n",
    "        best_feature[\"variance_reduced\"] = 0\n",
    "        \n",
    "        maximum_variance_reduction = -float(\"inf\") #initialise the maximum variance reduction varaiable which will be sed to keep track of current maximum\n",
    "        \n",
    "        for features in range(number_attributes): #iterate over all features\n",
    "            values = dataset[:, features] #extract the feature column\n",
    "            unique_sorted_values = np.unique(values) #find sorted and unique values\n",
    "            #possible threshold would be decided by taking mean of adjacent entries\n",
    "            threshold_array = np.array([(unique_sorted_values[i]+unique_sorted_values[i+1])/2 for i in range(0,len(unique_sorted_values)-1)])\n",
    "\n",
    "            for threshold in threshold_array: #iterate over all possible threshold values\n",
    "                dataset_left, dataset_right = self.split_left_right(dataset, features, threshold) #split the data according to the feature and threshold\n",
    "                \n",
    "                if len(dataset_left)>0 and len(dataset_right)>0: #if two partitions are created\n",
    "                    \n",
    "                    dataset_y, dataset_left_y, dataset_right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]#extract target variable columns\n",
    "                    \n",
    "                    variance_reduced = self.variance_reduction(dataset_y, dataset_left_y, dataset_right_y)#calculate the reduction in variance caused by this split\n",
    "                    if variance_reduced > maximum_variance_reduction:#if the variance reduction caused is more than the current maxima\n",
    "                        #update the feature dictionary and store all relevant details\n",
    "                        best_feature[\"attribute\"] = features\n",
    "                        best_feature[\"threshold\"] = threshold\n",
    "                        best_feature[\"dataset_left\"] = dataset_left\n",
    "                        best_feature[\"dataset_right\"] = dataset_right\n",
    "                        best_feature[\"variance_reduced\"] = variance_reduced\n",
    "                        maximum_variance_reduction = variance_reduced # update the current maxima and continue iterating over all possible combinations \n",
    "                        \n",
    "        return best_feature # return the maximum variance reducing feature dictionary\n",
    "    \n",
    "    def construct_tree(self, dataset, current_depth=0): #function to construct tree\n",
    "        \n",
    "        X, y = dataset[:,:-1], dataset[:,-1] #extract feature matrix and target variable vector from dataset\n",
    "        number_datapoints, number_attributes = np.shape(X) \n",
    "        current_best_feature = {} #to keep a track of the best splitting attribute for current node \n",
    "        \n",
    "        if number_datapoints >= self.minimum_samples:# and current_depth <= self.max_depth: #if the stopping conditions are not yet reached\n",
    "            current_best_feature = self.get_best_feature(dataset, number_datapoints, number_attributes) #get the best splitting attribute for the node\n",
    "            if current_best_feature[\"variance_reduced\"]>0: #if the variance reduction is positive that is the data has been splitted in 2 fractions \n",
    "                subtree_left = self.construct_tree(current_best_feature[\"dataset_left\"], current_depth+1) #call construct tree recursively for left subtree\n",
    "                subtree_right = self.construct_tree(current_best_feature[\"dataset_right\"], current_depth+1)#call construct tree recursively for rigjt subtree\n",
    "                return Node(current_best_feature[\"attribute\"], current_best_feature[\"threshold\"],subtree_left, subtree_right, current_best_feature[\"variance_reduced\"],current_depth)\n",
    "                #return a node with left subtree as left child and right subtree as right child\n",
    "        \n",
    "        #in case the depth is exhausted or we are left with datapoint less than minimum_samples at a node we make that node a leaf node\n",
    "        leaf_value = self.cal_leaf_node(y)#calculate the laef value \n",
    "        return Node(level = current_depth,leaf_value = leaf_value)#return the leaf node\n",
    "    \n",
    "    \n",
    "    def print_decision_tree(self,columns,decision_tree=None,indent=\" \",curr = 0,depth=[]):\n",
    "        \n",
    "        depth.append(curr)\n",
    "        if decision_tree.leaf_value is not None: #if decision_tree points to a leaf node simply print the value\n",
    "            print(\"Leaf: \",round(decision_tree.leaf_value,3))\n",
    "\n",
    "        else:#if decision tree points to a decision node\n",
    "            #print the node splitting details\n",
    "            print(columns[decision_tree.attribute], \"==>\", round(decision_tree.threshold,3), \"(\", round(decision_tree.variance_red,3),\")\")\n",
    "            \n",
    "            #print the left subtree by recursive calling the function and indentation increasing at every depth\n",
    "            print(\"%sLeft: \" % (indent), end=\"\")\n",
    "            self.print_decision_tree(columns, decision_tree.child_left, indent+indent,curr+1,depth)\n",
    "            \n",
    "            #print the right subtree by recursive calling the function and indentation increasing at every depth\n",
    "            print(\"%sRight: \" % (indent), end=\"\")\n",
    "            self.print_decision_tree(columns, decision_tree.child_right, indent+indent,curr+1,depth)\n",
    "    \n",
    "    def fit_model(self, X, y): #train a model to fit X and y\n",
    "        \n",
    "        dataset = np.concatenate((X, y), axis=1)#concatenate X and y to create the dataset\n",
    "        self.root = self.construct_tree(dataset)#train the tree and store the final returned node in root\n",
    "        \n",
    "    def predict(self, data, decision_tree=None):#to predict target variable for a datapoint x\n",
    "        \n",
    "        #basic algo is to traverse the graph depending upon splitting feature and threshold values\n",
    "\n",
    "        if decision_tree.leaf_value!=None: #if you have reached a leaf node simply return the value of the leaf\n",
    "            return decision_tree.leaf_value\n",
    "        \n",
    "        attribute_value = data[decision_tree.attribute]#else extract the value at splitting attrribute column in x  \n",
    "        if attribute_value <= decision_tree.threshold: # check if the value is less than or equal to threshold\n",
    "            return self.predict(data, decision_tree.child_left)#traverse to the left subtree \n",
    "        else:\n",
    "            return self.predict(data, decision_tree.child_right)#else traverse to the right subtree\n",
    "        \n",
    "\n",
    "    def post_pruning(self,root,decision_tree,dataset,error,depth=[]):\n",
    "        \n",
    "        X = dataset[:,:-1]\n",
    "        y = dataset[:,-1]\n",
    "        if decision_tree.leaf_value is not None:\n",
    "            return root\n",
    "        \n",
    "        if decision_tree.leaf_value is None: #if the node is a decision node\n",
    "            decision_tree.leaf_value = self.cal_leaf_node(y)#assign the corresponding leaf value\n",
    "            y_pred = [self.predict(x,root) for x in X]#make predictions on the new tree\n",
    "            \n",
    "            #base condition\n",
    "            if (mean_error(y_pred,y,X.shape[0])) < error:#if the tree is succesful in reducing the error\n",
    "                error = mean_error(y_pred,y,X.shape[0])\n",
    "                changenode(root,decision_tree,None,None,self.cal_leaf_node(y))\n",
    "                return root#return the root which now has the particular node converted to leaf node\n",
    "            \n",
    "            #recursive defination\n",
    "            else: \n",
    "                \n",
    "                #in case truncating the branch doesn't help\n",
    "                decision_tree.leaf_value=None \n",
    "            \n",
    "                left,right = self.split_left_right(dataset,decision_tree.attribute,decision_tree.threshold)\n",
    "                leftn = self.post_pruning(root,decision_tree.child_right,right,error,depth)\n",
    "                    \n",
    "                rightn = self.post_pruning(root,decision_tree.child_right,right,error,depth)#prune the right subtree recursively\n",
    "                    \n",
    "                changenode(root, decision_tree,leftn,rightn,None)\n",
    "                num = num_nodes(root)\n",
    "                y_pred = [self.predict(x,root) for x in X]\n",
    "                error = mean_error(y_pred,y,X.shape[0])\n",
    "                a = {'num':num,'error':error}\n",
    "                depth.append(a)\n",
    "                return root#create a node with the pruned left subtree and pruned right subtree as left child and right child respectively \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2095ecca",
   "metadata": {},
   "source": [
    "#### Error function that will help us in pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "88efa00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_height(decision_tree,height=[]):\n",
    "    if decision_tree.leaf_value is not None:\n",
    "        height.append(decision_tree.level)\n",
    "        return\n",
    "    else:\n",
    "        find_height(decision_tree.child_left,height)\n",
    "        find_height(decision_tree.child_right,height)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "93409706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_error(y_pred, y_actual, n): # to calculate root mean square error of the predictions\n",
    "    \n",
    "    sum=0\n",
    "    for i in range(n): #iterate over all n datapoints\n",
    "        sum = sum+(y_pred[i]-y_actual[i])**2 #add to sum the square of the difference between prediction and actual label\n",
    "    \n",
    "    sum = sum/n #take mean of the sum\n",
    "    sum = np.sqrt(sum) #take square root of the error\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc2505bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changenode(root,node, child_left,child_right,leaf_value):\n",
    "     \n",
    "    if root == node:\n",
    "        root.child_left = child_left\n",
    "        root.child_right = child_right\n",
    "        root.leaf_value  = leaf_value\n",
    "        return root\n",
    " \n",
    "    if root.child_left is not None:\n",
    "        root.child_left = changenode(root.child_left,node, child_left,child_right,leaf_value)\n",
    " \n",
    "    elif root.child_right is not None:\n",
    "        root.child_right = changenode(root.child_right,node, child_left,child_right,leaf_value)\n",
    "         \n",
    "    return root\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae3a11c",
   "metadata": {},
   "source": [
    "#### To select the maximum efficient data split we randomly split the data in 10 sample with 70-30 split and select the distribution that gives us minimum error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2dd5a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error=float(\"inf\") #initialise the minimum error\n",
    "\n",
    "for i in range(1): #repeat for 10 splits\n",
    "    d = data.sample(frac = 1,random_state=42) #returns a randomly jumbles data\n",
    "    \n",
    "    div = int(0.7 * d.shape[0])#calculate 70 percent of the number of input datapoints\n",
    "    d_train, d_test = d.iloc[:div,:], d.iloc[div:,:]#split the data into test and train\n",
    "    \n",
    "    d_train_x = d_train.iloc[:,:-1].values#set training data featutre matrix\n",
    "    d_train_y = d_train.iloc[:,-1].values.reshape(-1,1)#set training data output label\n",
    "    d_test_x = d_test.iloc[:,:-1].values#set test data feature matrix\n",
    "    d_test_y = d_test.iloc[:,-1].values.reshape(-1,1)#set test data output label\n",
    "    \n",
    "    regress_tree = RegressionTree(minimum_samples=2)#construct a regression tree of depth 30(arbitarily large to allow best tree depending upon training set)\n",
    "    regress_tree.fit_model(d_train_x,d_train_y)\n",
    "    y_pred_train = [regress_tree.predict(x,regress_tree.root)  for x in d_train_x]#construct the predicted output variable vector\n",
    "    \n",
    "    if mean_error(y_pred_train,d_train_y,d_train_x.shape[0])<min_error: #if the error of this tree is less than the current minima\n",
    "        min_error = mean_error(y_pred_train,d_train_y,d_train_x.shape[0]) #update current minima\n",
    "        dataset_train = d_train#save the current training dataset\n",
    "        dataset_test = d_test#save the current test set\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c2ef06f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height=[]\n",
    "find_height(regress_tree.root,height)\n",
    "height\n",
    "max(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e76e8a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cement', 'slag', 'flyash', 'water', 'superplasticizer',\n",
       "       'coarseaggregate', 'fineaggregate', 'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = data.iloc[:,:-1].columns #extract the columns of the training data\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d35be2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x = dataset_train.iloc[:,:-1].values #extract training data feature matrix after best splitting found\n",
    "data_train_y = dataset_train.iloc[:,-1].values.reshape(-1,1) #extract training data target label vector after best splitting found\n",
    "data_test_x = dataset_test.iloc[:,:-1].values #extract test data feature matrix after best splitting found\n",
    "data_test_y = dataset_test.iloc[:,-1].values.reshape(-1,1) #extract test data target label vector after best splitting found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636cc4c",
   "metadata": {},
   "source": [
    "#### We can clearly see the optimal depth of the tree should be around 15 but our present tree has depth 30 which leads to overfitting. The train error has reduced significantly but the tree fails to generalize well on unseen data. Thus, Post-pruning is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d7b3aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_nodes(decision_tree):\n",
    "    l_nodes = 0\n",
    "    r_nodes = 0\n",
    "    if decision_tree.leaf_value is not None:\n",
    "        return 1\n",
    "    else:\n",
    "        l_nodes = num_nodes(decision_tree.child_left)\n",
    "        r_nodes = num_nodes(decision_tree.child_right)\n",
    "        return l_nodes+r_nodes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ffa6529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_tree = RegressionTree(minimum_samples=2)\n",
    "regress_tree.fit_model(data_train_x,data_train_y)#train a tree of heights 30\n",
    "        \n",
    "y_original = [regress_tree.predict(x,regress_tree.root) for x in data_test_x] #calculate test error\n",
    "err = mean_error(y_original,data_test_y,data_test_x.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = regress_tree.root\n",
    "X = dataset_test.iloc[:,:-1].values\n",
    "y = dataset_test.iloc[:,-1].values.reshape(-1,1)\n",
    "dataset = np.concatenate((X, y), axis=1)\n",
    "\n",
    "d=[]\n",
    "pruned = regress_tree.post_pruning(regress_tree.root,tree,dataset,err,d,dataset)\n",
    "\n",
    "\n",
    "print(\"Error before pruning: \",mean_error(y_original,data_test_y,data_test_x.shape[0]))\n",
    "\n",
    "y_pred_test = [regress_tree.predict(data = x,decision_tree=pruned) for x in data_test_x] \n",
    "\n",
    "print(\"Error after pruning: \",mean_error(y_pred_test,data_test_y,data_test_x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=[]\n",
    "regress_tree.print_decision_tree(columns,pruned,\" \",0,depth = depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0372b85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_pruned = max(depth)\n",
    "depth_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a78d770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num': 3, 'error': 5.330660333985565},\n",
       " {'num': 5, 'error': 5.233780824830395},\n",
       " {'num': 3, 'error': 4.627913368123602},\n",
       " {'num': 5, 'error': 4.627913368123602},\n",
       " {'num': 7, 'error': 4.627913368123602},\n",
       " {'num': 9, 'error': 6.132008235480444},\n",
       " {'num': 15, 'error': 5.357709918644749},\n",
       " {'num': 3, 'error': 3.5445968270970782},\n",
       " {'num': 5, 'error': 4.345198499493436},\n",
       " {'num': 9, 'error': 4.345198499493436},\n",
       " {'num': 13, 'error': 4.345198499493436},\n",
       " {'num': 3, 'error': 3.756589290199036},\n",
       " {'num': 5, 'error': 3.649237610637171},\n",
       " {'num': 19, 'error': 3.8669563321182987},\n",
       " {'num': 3, 'error': 14.38254150002704},\n",
       " {'num': 5, 'error': 14.38254150002704},\n",
       " {'num': 7, 'error': 14.38254150002704},\n",
       " {'num': 15, 'error': 14.38254150002704},\n",
       " {'num': 3, 'error': 8.651820617650369},\n",
       " {'num': 9, 'error': 8.651820617650369},\n",
       " {'num': 25, 'error': 11.555181617881315},\n",
       " {'num': 3, 'error': 2.8272925800725566},\n",
       " {'num': 29, 'error': 9.417566855413902},\n",
       " {'num': 49, 'error': 6.946511977670088},\n",
       " {'num': 65, 'error': 5.891114956413394},\n",
       " {'num': 3, 'error': 0.0},\n",
       " {'num': 5, 'error': 0.1131370849898477},\n",
       " {'num': 7, 'error': 4.1853134731795505},\n",
       " {'num': 9, 'error': 4.96603892737513},\n",
       " {'num': 11, 'error': 5.0727957307831275},\n",
       " {'num': 3, 'error': 3.413669823908965},\n",
       " {'num': 5, 'error': 4.434676058747894},\n",
       " {'num': 3, 'error': 3.9133568284359996},\n",
       " {'num': 5, 'error': 4.090560945363928},\n",
       " {'num': 3, 'error': 3.8862462608537816},\n",
       " {'num': 5, 'error': 3.515125602307832},\n",
       " {'num': 3, 'error': 0.0070710678118640685},\n",
       " {'num': 9, 'error': 3.208857273236066},\n",
       " {'num': 15, 'error': 3.8408859117259113},\n",
       " {'num': 17, 'error': 3.840842701260566},\n",
       " {'num': 23, 'error': 4.008540558873207},\n",
       " {'num': 3, 'error': 9.952379461437575},\n",
       " {'num': 7, 'error': 9.952379461437575},\n",
       " {'num': 9, 'error': 8.797308833292902},\n",
       " {'num': 3, 'error': 4.9386968109488345},\n",
       " {'num': 5, 'error': 4.549529076158851},\n",
       " {'num': 15, 'error': 6.88316392280725},\n",
       " {'num': 19, 'error': 6.88316392280725},\n",
       " {'num': 21, 'error': 6.88316392280725},\n",
       " {'num': 5, 'error': 9.095123235375464},\n",
       " {'num': 7, 'error': 9.095123235375464},\n",
       " {'num': 9, 'error': 9.095123235375464},\n",
       " {'num': 17, 'error': 9.095123235375464},\n",
       " {'num': 19, 'error': 9.095123235375464},\n",
       " {'num': 21, 'error': 7.876607772385268},\n",
       " {'num': 3, 'error': 3.5945251579466104},\n",
       " {'num': 25, 'error': 5.706903421880089},\n",
       " {'num': 27, 'error': 5.44131891320032},\n",
       " {'num': 35, 'error': 5.44131891320032},\n",
       " {'num': 37, 'error': 5.224545115765263},\n",
       " {'num': 3, 'error': 5.372628402595972},\n",
       " {'num': 41, 'error': 5.309099281439384},\n",
       " {'num': 63, 'error': 5.850493611126087},\n",
       " {'num': 3, 'error': 3.7638721196838385},\n",
       " {'num': 5, 'error': 3.9048111349974377},\n",
       " {'num': 7, 'error': 4.987623118781129},\n",
       " {'num': 9, 'error': 5.250196821707417},\n",
       " {'num': 73, 'error': 5.768562827078084},\n",
       " {'num': 97, 'error': 5.01781551431307},\n",
       " {'num': 109, 'error': 5.032216091752287},\n",
       " {'num': 3, 'error': 2.440023906986705},\n",
       " {'num': 3, 'error': 1.4533639140513532},\n",
       " {'num': 7, 'error': 2.0754230779243428},\n",
       " {'num': 3, 'error': 5.07433246841395},\n",
       " {'num': 3, 'error': 13.673706520179522},\n",
       " {'num': 9, 'error': 13.673706520179522},\n",
       " {'num': 11, 'error': 8.926249445689196},\n",
       " {'num': 15, 'error': 7.622748684037799},\n",
       " {'num': 17, 'error': 7.268005697451111},\n",
       " {'num': 19, 'error': 6.508691853426243},\n",
       " {'num': 27, 'error': 5.447737152191273},\n",
       " {'num': 3, 'error': 14.06438231846674},\n",
       " {'num': 5, 'error': 14.06438231846674},\n",
       " {'num': 7, 'error': 7.93979470767349},\n",
       " {'num': 9, 'error': 9.675677754038734},\n",
       " {'num': 13, 'error': 9.675677754038734},\n",
       " {'num': 15, 'error': 8.182532789860538},\n",
       " {'num': 23, 'error': 8.062077364338016},\n",
       " {'num': 3, 'error': 4.190966475647354},\n",
       " {'num': 27, 'error': 7.2467062572555925},\n",
       " {'num': 55, 'error': 6.3659542129728415},\n",
       " {'num': 165, 'error': 5.324331610828347},\n",
       " {'num': 231, 'error': 5.520365277863}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ffd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.savefig('filename.jpg',bbox_inches='tight', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee1f9c3c93c55bb4af787bd902f8445c3aef2fd2438d66b6fa4059ca904d1856"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
